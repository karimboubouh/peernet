{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd import grad, jacobian, hessian\n",
    "from autograd.scipy.stats import norm\n",
    "import time\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import fsolve\n",
    "from autograd import grad\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(X):\n",
    "    x, y, z = X\n",
    "    return x**2 + y**2 + z**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eq(X):\n",
    "    x, y, z = X\n",
    "    return 2 * x - y + z - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol = minimize(objective, [1, -0.5, 0.5], constraints={'type': 'eq', 'fun': eq})\n",
    "sol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F(L):\n",
    "    'Augmented Lagrange function'\n",
    "    x, y, z, _lambda = L\n",
    "    return objective([x, y, z]) - _lambda * eq([x, y, z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradients of the Lagrange function\n",
    "dfdL = grad(F, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find L that returns all zeros in this function.\n",
    "def obj(L):\n",
    "    x, y, z, _lambda = L\n",
    "    dFdx, dFdy, dFdz, dFdlam = dfdL(L)\n",
    "    return [dFdx, dFdy, dFdz, eq([x, y, z])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, z, _lam = fsolve(obj, [0.0, 0.0, 0.0, 1.0])\n",
    "print(f'The answer is at {x, y, z}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[]])\n",
    "m = X.shape[0]\n",
    "Y = []\n",
    "t1 = z1 = np.array([[ 0.00043896], [ 0.00058852], [-0.00043738], [ 0.00101669]])\n",
    "t2 = z2 = np.array([[ 0.00119033], [ 0.00065769], [-0.00014218], [ 0.0018238 ]])\n",
    "t3 = z3 = np.array([[ 0.00029429], [ 0.0004789 ], [-0.00032502], [ 0.00110983]])\n",
    "\n",
    "Theta = {'w1': t1, 'w2': t2, 'w3': t3}\n",
    "Zed = {'w1': z1, 'w2': z2, 'w3': z3}\n",
    "AA = {'w1': 0, 'w2': 0, 'w3': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F(L):\n",
    "    'Augmented Lagrange function'\n",
    "    T, Z, A = L\n",
    "    \n",
    "    q = np.sum(np.array([np.linalg.norm(T - Theta[j])**2 for j in Theta]), axis=0)\n",
    "    a = np.sum( A * (T - Z) +  np.array([np.linalg.norm(T - Theta[j])**2 for j in Theta]), axis=0)\n",
    "    return objective([x, y, z]) - _lambda * eq([x, y, z])\n",
    "\n",
    "\n",
    "np.sum(np.array([w * np.linalg.norm(T[i] - T[j]) ** 2 for j, w in node.W.items()]), axis=0)\n",
    "\n",
    "\n",
    "\n",
    "sigma_Q = \n",
    "            sigma_A = np.sum(np.array([node.A[i] + node.rho * (T[i] - node.Z[i]) for _ in node.Theta]), axis=0)\n",
    "            cl_dw = sigma_Q + node.mu * node.D * dw + sigma_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import optimize\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import joblib\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Minimizing the Rosenbrock Function\n",
    "# ============================\n",
    "def rosenbrock(x):    \n",
    "    return sum(100.0*(x[1:]-x[:-1]**2.0)**2.0 + (1-x[:-1])**2.0)\n",
    "\n",
    "x0 = np.array([1.3, 0.7, 1.8, 2.9, 1.8])\n",
    "res = optimize.minimize(rosenbrock, x0, method='nelder-mead', options={'xtol': 1e-8, 'disp': True})\n",
    "res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Function to compute gradient\n",
    "# ============================\n",
    "def rosen_grad(x):\n",
    "    xm = x[1:-1]\n",
    "    xm_m1 = x[:-2]\n",
    "    xm_p1 = x[2:]\n",
    "    der = np.zeros_like(x)\n",
    "    der[1:-1] = 200*(xm-xm_m1**2) - 400*(xm_p1 - xm**2)*xm - 2*(1-xm)\n",
    "    der[0] = -400*x[0]*(x[1]-x[0]**2) - 2*(1-x[0])\n",
    "    der[-1] = 200*(x[-1]-x[-2]**2)\n",
    "    return der\n",
    "\n",
    "res = optimize.minimize(rosenbrock, x0, method='BFGS', jac=rosen_grad, options={'disp': True})\n",
    "res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining data generator\n",
    "def generate_data(t, A, sigma, omega, noise=0, n_outliers=0, random_state=0):\n",
    "    y = A * np.exp(-sigma * t) * np.sin(omega * t)\n",
    "    rnd = np.random.RandomState(random_state)\n",
    "    error = noise * rnd.randn(t.size)\n",
    "    outliers = rnd.randint(0, t.size, n_outliers)\n",
    "    error[outliers] *= 35\n",
    "    return y + error\n",
    "\n",
    "# Model parameters\n",
    "A = 2\n",
    "sigma = 0.1\n",
    "omega = 0.1 * 2 * np.pi\n",
    "x_true = np.array([A, sigma, omega])\n",
    "noise = 0.1\n",
    "t_min = 0\n",
    "t_max = 30\n",
    "\n",
    "# Outliers\n",
    "t_train = np.linspace(t_min, t_max, 30)\n",
    "y_train = generate_data(t_train, A, sigma, omega, noise=noise, n_outliers=4)\n",
    "\n",
    "# Function to compute residuals of least-squares\n",
    "def fun(x, t, y):\n",
    "    return x[0] * np.exp(-x[1] * t) * np.sin(x[2] * t) - y\n",
    "\n",
    "# Initial estimate\n",
    "x0 = np.ones(3)\n",
    "\n",
    "# Running standard least-squares\n",
    "res_lsq = optimize.least_squares(fun, x0, args=(t_train, y_train))\n",
    "\n",
    "# Running robust least-squares\n",
    "res_robust = optimize.least_squares(fun, x0, loss='soft_l1', f_scale=0.1, args=(t_train, y_train))\n",
    "\n",
    "# Visualization\n",
    "t_test = np.linspace(t_min, t_max, 300)\n",
    "y_test = generate_data(t_test, A, sigma, omega)\n",
    "y_lsq = generate_data(t_test, *res_lsq.x)\n",
    "y_robust = generate_data(t_test, *res_robust.x)\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(t_train, y_train, 'o', label='data')\n",
    "plt.plot(t_test, y_test, label='true')\n",
    "plt.plot(t_test, y_lsq, label='lsq')\n",
    "plt.plot(t_test, y_robust, label='robust lsq')\n",
    "plt.xlabel('$t$')\n",
    "plt.ylabel('$y$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import optimize\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import joblib\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"./datasets/mnist.data\"\n",
    "X, y = joblib.load(dataset)\n",
    "y = y.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X[:500]\n",
    "y_train = y[:500]\n",
    "x_test = X[60000:]\n",
    "y_test = y[60000:]\n",
    "y_train = np.squeeze(y_train)\n",
    "x_train = x_train[np.any([y_train == 1, y_train == 2], axis = 0)]\n",
    "y_train = y_train[np.any([y_train == 1, y_train == 2], axis = 0)]\n",
    "y_train = y_train - 1\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = np.squeeze(y_test)\n",
    "x_test = x_test[np.any([y_test == 1, y_test == 2], axis = 0)]\n",
    "y_test = y_test[np.any([y_test == 1, y_test == 2], axis = 0)]\n",
    "y_test = y_test - 1\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "m = x_train.shape[0]\n",
    "m_test = x_test.shape[0]\n",
    "x_train, x_test = x_train.T, x_test.T\n",
    "y_train, y_test = y_train.reshape(1,m), y_test.reshape(1,m_test)\n",
    "np.random.seed(138)\n",
    "shuffle_index = np.random.permutation(m)\n",
    "X_train, y_train = x_train[:,shuffle_index], y_train[:,shuffle_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((784, 118), (1, 118))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    s = 1.0 / (1.0 + np.exp(-z))\n",
    "    return s\n",
    "def compute_loss(Y, Y_hat):\n",
    "\n",
    "    m = Y.shape[1]\n",
    "    L = -(1./m) * ( np.sum( np.multiply(np.log(Y_hat),Y) ) + np.sum( np.multiply(np.log(1-Y_hat),(1-Y)) ) )\n",
    "\n",
    "    return L\n",
    "\n",
    "learning_rate = 0.05\n",
    "\n",
    "X = X_train\n",
    "Y = y_train\n",
    "\n",
    "n_x = X.shape[0]\n",
    "m = X.shape[1]\n",
    "\n",
    "W = np.random.randn(n_x, 1) * 0.01\n",
    "b = np.zeros((1, 1))\n",
    "\n",
    "for i in range(2000):\n",
    "    Z = np.matmul(W.T, X) + b\n",
    "    A = sigmoid(Z)\n",
    "\n",
    "    cost = compute_loss(Y, A)\n",
    "\n",
    "    dW = (1/m) * np.matmul(X, (A-Y).T)\n",
    "    db = (1/m) * np.sum(A-Y, axis=1, keepdims=True)\n",
    "\n",
    "    W = W - learning_rate * dW\n",
    "    b = b - learning_rate * db\n",
    "\n",
    "    if (i % 200 == 0):\n",
    "        print(\"Epoch\", i, \"cost: \", cost)\n",
    "\n",
    "print(\"Final cost:\", cost)\n",
    "\n",
    "Z = np.matmul(W.T, x_test) + b\n",
    "A = sigmoid(Z)\n",
    "\n",
    "predictions = (A>.5)[0,:]\n",
    "\n",
    "print(predictions.shape, A.shape)\n",
    "labels = (y_test == 1)[0,:]\n",
    "\n",
    "accuracy_score(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append({\"W\": W, \"b\": b})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joblib.dump(models, 'models.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = joblib.load('./models.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(models[2][\"W\"] - models[1][\"W\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.sum((models[2][\"W\"] - models[1][\"W\"])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj(theta, i=1):\n",
    "    m = X.shape[1]\n",
    "\n",
    "    z = np.dot(theta.T, X_train) + models[i][\"b\"]\n",
    "\n",
    "    A = sigmoid(z)\n",
    "\n",
    "    cost = -1.0/m * np.sum(y_train * np.log(A) + (1.0 - y_train) * np.log(1.0 - A))\n",
    "\n",
    "#     sigmaQ = np.sum(np.array([0.6 * (np.sqrt(np.sum((theta - model[\"W\"])**2))) ** 2 for model in models]), axis=0)\n",
    "    \n",
    "#     Q = 0.5 * sigmaQ * 0.5 * 2 * cost\n",
    "    \n",
    "    print(cost)\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "jacobian_ = jacobian(obj)\n",
    "theta_start  = models[i][\"W\"]\n",
    "b_start  = models[i][\"b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj(theta_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jacobian_(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jacobian_(theta_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jacobian_(theta_start)\n",
    "\n",
    "print(\"Initial loss:\", obj(theta_start))\n",
    "for i in range(1):\n",
    "    theta_start -= jacobian_(theta_start) * 0.01\n",
    "\n",
    "print(\"Trained loss:\", obj(theta_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "res = optimize.minimize(obj, theta_start, method='BFGS', options={'disp': False}, jac=jacobian_)\n",
    "\n",
    "print(f\"Optimization done in {time.time() - start_time} seconds\")\n",
    "res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize.minimize(rosenbrock, x0, method='BFGS', jac=rosen_grad, options={'disp': True})\n",
    "res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from builtins import range\n",
    "#import autograd.numpy as np\n",
    "import numpy as np\n",
    "from autograd import grad\n",
    "from autograd.test_util import check_grads\n",
    "\n",
    "models = joblib.load('./models.data')\n",
    "i = 0\n",
    "theta_start  = models[i][\"W\"]\n",
    "m = X_train.shape[1]\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 0.5*(np.tanh(x) + 1)\n",
    "\n",
    "def logistic_predictions(weights, inputs):\n",
    "    # Outputs probability of a label being true according to logistic model.\n",
    "    return sigmoid(np.dot(inputs.T, weights))\n",
    "\n",
    "def training_loss(weights):\n",
    "    # Training loss is the negative log-likelihood of the training labels.\n",
    "    preds = logistic_predictions(weights, inputs)\n",
    "    label_probabilities = preds * targets + (1 - preds) * (1 - targets)\n",
    "    print(-np.sum(np.log(label_probabilities)))\n",
    "    return (1/m) * -np.sum(np.log(label_probabilities))\n",
    "\n",
    "# Build a toy dataset.\n",
    "inputs = X_train\n",
    "targets = y_train\n",
    "\n",
    "# Build a function that returns gradients of training loss using autograd.\n",
    "training_gradient_fun = grad(training_loss)\n",
    "\n",
    "# Check the gradients numerically, just to be safe.\n",
    "weights = np.zeros((X_train.shape[0], 1))\n",
    "check_grads(training_loss, modes=['rev'])(weights)\n",
    "print(weights.shape)\n",
    "\n",
    "# Optimize weights using gradient descent.\n",
    "print(\"Initial loss:\", training_loss(weights))\n",
    "for i in range(500):\n",
    "    weights -= training_gradient_fun(weights) * 0.01\n",
    "\n",
    "print(\"Trained loss:\", training_loss(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros((3, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-fff2ed71429f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Form objective.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMinimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# Form and solve problem.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-fff2ed71429f>\u001b[0m in \u001b[0;36mL\u001b[0;34m(theta)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"b\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mm\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-fff2ed71429f>\u001b[0m in \u001b[0;36msigmoid\u001b[0;34m(z)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/phd/PeerNet/.env/lib/python3.7/site-packages/cvxpy/atoms/elementwise/exp.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Returns the matrix e^x[i, j].\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/phd/PeerNet/.env/lib/python3.7/site-packages/cvxpy/atoms/atom.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     41\u001b[0m             )\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# Convert raw values to Constants.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mAtom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast_to_const\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_from_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/phd/PeerNet/.env/lib/python3.7/site-packages/cvxpy/atoms/atom.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     41\u001b[0m             )\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# Convert raw values to Constants.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mAtom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast_to_const\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_from_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/phd/PeerNet/.env/lib/python3.7/site-packages/cvxpy/expressions/expression.py\u001b[0m in \u001b[0;36mcast_to_const\u001b[0;34m(expr)\u001b[0m\n\u001b[1;32m    444\u001b[0m         \"\"\"Converts a non-Expression to a Constant.\n\u001b[1;32m    445\u001b[0m         \"\"\"\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mexpr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExpression\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mcvxtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_cast_other\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/phd/PeerNet/.env/lib/python3.7/site-packages/cvxpy/expressions/constants/constant.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT_INTF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconst_to_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_imag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/phd/PeerNet/.env/lib/python3.7/site-packages/cvxpy/interface/numpy_interface/ndarray_interface.py\u001b[0m in \u001b[0;36mconst_to_matrix\u001b[0;34m(self, value, convert_scalars)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m# Return an identity matrix.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "models = joblib.load('./models.data')\n",
    "i = 1\n",
    "theta_start  = models[i][\"W\"]\n",
    "b_start  = models[i][\"b\"]\n",
    "\n",
    "def sigmoid(z):\n",
    "    s = 1.0 / (1.0 + cp.exp(-z))\n",
    "    return s\n",
    "\n",
    "\n",
    "def L(theta):\n",
    "    m = X.shape[1]\n",
    "\n",
    "    z = np.dot(theta.T, X_train) + models[i][\"b\"]\n",
    "\n",
    "    A = sigmoid(z)\n",
    "\n",
    "    cost = -1.0/m * np.sum(y_train * np.log(A) + (1.0 - y_train) * np.log(1.0 - A))\n",
    "\n",
    "#     sigmaQ = np.sum(np.array([0.6 * (np.sqrt(np.sum((theta - model[\"W\"])**2))) ** 2 for model in models]), axis=0)\n",
    "    \n",
    "#     Q = 0.5 * sigmaQ * 0.5 * 2 * cost\n",
    "    \n",
    "    print(cost)\n",
    "    \n",
    "    return cost\n",
    "\n",
    "\n",
    "\n",
    "# Create two scalar optimization variables.\n",
    "x = cp.Variable(theta_start.shape)\n",
    "x.value = theta_start\n",
    "\n",
    "# Form objective.\n",
    "obj = cp.Minimize(L(x))\n",
    "\n",
    "# Form and solve problem.\n",
    "prob = cp.Problem(obj)\n",
    "prob.solve()  # Returns the optimal value.\n",
    "print(\"status:\", prob.status)\n",
    "print(\"optimal value\", prob.value)\n",
    "print(\"optimal var\", x.value, y.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp.Variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PeerNet",
   "language": "python",
   "name": "peernet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
